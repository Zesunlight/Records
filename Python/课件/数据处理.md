### 数据清洗 (data cleaning) 

数据清洗的结果是对各种脏数据进行对应方式的处理，得到标准的、干净的、连续的数据，提供给数据统计、数据挖掘等使用。

数据清理的主要思想是通过填补缺失值、光滑噪声数据，平滑或删除离群点，并解决数据的不一致性来“清理“数据。

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

csv_path = r'A:\Python课程\10月\rz.csv'
dataset = pd.read_csv(csv_path)

dataset.info()
dataset.head()
dataset.shape
dataset.columns
dataset = dataset.drop('Unnamed: 0', axis = 1)
dataset.describe()
dataset['班级'].unique()  # 所有的唯一值
dataset['班级'].nunique()  # 有多少个唯一值
df1['性别'].value_counts()  # 每个元素有多少个
dataset['姓名'].count()  # 非缺失值元素个数
dataset[dataset['数分'] < 60]
dataset['数分'].idxmax()  # 最大值所在索引
dataset['数分'].nlargest(3)  # 前几个大的元素值  nsmallest
dataset['数分'].clip(33,80)  # 对超过或者低于某些值的数进行截断
dataset.sort_values(by='数分')  # df.sort_values(by=['Address','Height']) 主次排序
```

#### 异常值

```python
dataset.duplicated()
dataset.iloc[20]
df1=dataset.drop_duplicates()  # 删除重复值
df1.shape

test = dataset.copy()
for i in range(test.shape[0]):
    for j in range(4, test.shape[1]):
        if test.iloc[i, j] == '作弊' or test.iloc[i, j] == '缺考':
            test.iloc[i, j] = 0

test['体育'] = test['体育'].astype('float64')
# test['体育'] = pd.to_numeric(test['体育'])
test.mean()
```

`pandas.DataFrame.duplicated(self, subset=None, keep=’first’)`

`pandas.Series.duplicated(self, keep=’first’)` 

`subset`：用于识别重复的列标签或列标签序列，默认所有列标签

`keep=‘frist’`：除了第一次出现外，其余相同的被标记为重复

`keep=’last’`：除了最后一次出现外，其余相同的被标记为重复

`keep=False`：所有相同的都被标记为重复

##### 检测

通过寻找数据集中与其他观测值及均值差距最大的点作为异常

聚类方法检测，将类似的取值组织成“群”或“簇”，落在“簇”集合之外的值被视为离群点

##### 修正

按平均值平滑 ：对数据求平均值，用平均值替代该数据。

按边界值平滑：用距离较小的边界值替代数据。

#### 缺失值

```python
for col in df1.columns:
    print (str(col) + ' >>> Number of Missing Values:', len(df1[col][df1[col].isnull()]))

df1.isnull()  # 检测空值
df1.notna()
df1.isna().sum()
# df[df.notna().all(1)]  all就是全部非缺失值，如果是any就是至少有一个不是缺失值
df1.isnull().any()  #判断哪些列存在缺失值
df1[df1.isnull().values == True]
df2 = df1.fillna(0)  # 空数据填充为0
df2.iloc[14]

dataset.dropna()  # 删除空值，axis=0 为行
# dropna(axis=1, how='all')  可以选all或者any，表示全为缺失去除和存在缺失去除
dataset.fillna('?')
dataset.fillna(method='pad')  # 用上一个值填充ffill，bfill表示用后一个数据代替NaN

test = dataset.copy()
test.iloc[0, 5] = np.nan
test.iloc[2, 7] = np.nan
test.fillna(test.mean())
test.fillna({'体育': 100})

s = pd.Series([1,10,15,-5,-2,np.nan,np.nan,28])
s.interpolate().plot()  # interpolate会对缺失的值进行线性插值

ser = pd.Series(np.arange(1, 10.1, .25) ** 2 + np.random.randn(37))
missing = np.array([4, 13, 14, 15, 16, 17, 18, 20, 29])
ser[missing] = np.nan
methods = ['linear', 'quadratic', 'cubic']
df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})
df.plot()
```

##### 删除

实在补不全的，虽然很可惜，但也必须要剔除

通常不鼓励采用此方法，因为它会导致数据丢失，因为移除的属性值也可以为数据集带来价值。

##### 填充

通过其他信息补全，例如使用身份证件号码推算性别、籍贯、出生日期、年龄等

通过前后数据补全，例如时间序列缺数据了，可以使用前后的均值，缺的多了，可以使用平滑等处理

缺失值可替换为全局常量（例如“N/A”或“Unknown”）

根据数据分布，可使用平均值（适用于正态分布）或中间值（适用于非正态分布）来填充缺失值

可使用回归和决策树等算法来预测并替换缺失值

##### 降噪



### 数据变换

数据形状变换（行列尺度修改）（掌握）；数据维度修改（数据特性选择）（掌握）；数据条数修改（数据向量选取）（掌握）；
多行数据合并为一行（掌握）；
多列数据合并为一列（掌握）；
某行数据复制成多行（掌握）；
某列数据复制成多列（掌握）；

```python
arr=np.array([[1,2,3], [4,5,6]])
print('number of arr dimensions: ',arr.ndim)
print('~    ~    ~   shape: ',arr.shape)
print('~    ~    ~   size: ', arr.size)

a = np.arange(6)
a.shape = 2, 3  # 改变形状
b = a.reshape(3, 2) # 改变形状
c = a[np.newaxis, :] # 增加维度，行
np.expand_dims(a, axis = 0)
np.expand_dims(a, axis = 1)
d = c.squeeze() # 减少维度
e = b.transpose()  # e = b.T
f = np.concatenate((a, e), axis=1) # 拼接
g = f.flatten() # 降至一维
h = np.array((a, e)) # 组合

arr2=np.arange(2,8).reshape(2,3)
print(arr2[0][2]) # arr[行][列]，也可以用arr[行,列]
print(arr2[0,:]) # 用:来代表所有元素的意思
print(arr2[0,0:3]) # 表示输出第0行，从第0列到第2列所有元素
                   # 注意python索引一般是左闭右开

arr1=np.array([1,2,3,6])
arr2=np.arange(4)
arr3=np.arange(2,17,2).reshape(2,4)
np.append(arr1, arr2, axis=0)
np.append(arr1, arr2, axis=1)  # 会出现维度的问题，推荐用下面的函数
arr_hor=np.hstack((arr1,arr2)) # 水平合并，horizontal
arr_ver=np.vstack((arr1,arr3)) # 垂直合并，vertical

print('arr3: ',arr3)
print(np.split(arr3,4,axis=1)) # 将矩阵按列均分成4块
print(np.split(arr3,2,axis=0)) # 将矩阵按行均分成2块
print(np.hsplit(arr3,4)) # 将矩阵按列均分成4块
print(np.vsplit(arr3,2)) # 将矩阵按行均分成2块
print(np.array_split(arr3,3,axis=1)) # 将矩阵进行不均等划分

x = np.arange(1, 5).reshape(2, 2)
print(x)
print(np.repeat(x, 2))  # 对数组中的每一个元素进行复制
c = np.array([1,2,3,4])
print(np.tile(c,(4,2)))  # 复制的是多维数组本身

print(np.repeat(x, 3, axis=1))  # 在某一轴上进行复制，行
print(np.repeat(x, 3, axis=0))  # 列
print(np.repeat(x, (2, 1), axis=0))  # 对不同的行/列复制不同的次数
```

### 数据重构

选取指定数据集的特定行或特定列，生成新数据集（掌握）；
一个数据集拆分成多个数据集（掌握）；
多个数据集拼接成一个数据集（掌握）；

```python
df = pd.read_csv(r'A:\Python课程\10月\test_data\table.csv',index_col='ID')
df.head()

grouped_single = df.groupby('School')  # 经过groupby后会生成一个groupby对象，该对象本身不会返回任何东西，只有当相应的方法被调用才会起作用
grouped_single.get_group('S_1').head()
grouped_single.ngroups
grouped_mul = df.groupby(['School','Class'])
grouped_mul.get_group(('S_2','C_4'))
grouped_mul.size()
for name, group in grouped_single:
    print(name)
    print(group.head())
print([attr for attr in dir(grouped_single) if not attr.startswith('_')])

df.groupby(['Gender','School'])['Math'].mean()>=60
df.groupby(['Gender','School'])[['Math','Height']].mean()

df = pd.read_csv(r'A:\Python课程\10月\test_data\table.csv')
df_append = df.loc[:3,['Gender','Height']].copy()
s = pd.Series({'Gender':'F','Height':188},name='new_row')
df_append.append(s)
df_temp = pd.DataFrame({'Gender':['F','M'],'Height':[188,176]},index=['new_1','new_2'])
df_append.append(df_temp)

s = pd.Series(list('abcd'),index=range(4))
df_append.assign(Letter=s)  # assign 主要用于添加列
df_append.assign(col1=lambda x:x['Gender']*2, col2=s)
```

