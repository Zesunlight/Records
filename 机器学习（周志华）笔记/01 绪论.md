# 读书笔记 -《机器学习》- 周志华

## 第1章 绪论

### 1.1 引言

- 机器学习研究的主要内容，是关于计算机**从数据中**产生模型的**算法** 

- 另一本经典教材的作者Mitchell给出了一个形式化的定义，假设：

  - P：计算机程序在某任务类T上的性能。
  - T：计算机程序希望实现的任务类。
  - E：表示经验，即历史的数据集。

  若该计算机程序通过利用经验E在任务T上获得了性能P的改善，则称该程序对E进行了学习

- 模型可泛指从数据中学得的结果

### 1.2 基本术语

- 等价的概念
  - 示例，样本，特征向量
  - 属性，特征
  - 属性空间，样本空间，输入空间
  - 标记空间，输出空间
- 从数据中得到模型的过程称为“学习”或者“训练”，这个过程通过执行某个学习算法完成
- 学得的模型对应了关于数据的某种潜在规律，亦称“假设 (hypothesis)”，潜在规律自身为 ground-truth
- 欲预测的是离散值，该学习任务为**分类**；若为连续值，则为**回归** 
- **聚类**有助于了解数据的内在规律
- 学得的模型适用于新样本的能力，称为**泛化**能力
- 一般假设全体样本服从一个未知的分布 $\mathcal D$，我们获得的样本是独立同分布的，从而训练样本越多，得到的关于 $\mathcal D$ 的信息也就越多

### 1.3 假设空间

- 归纳，特殊到一般；演绎，一般到特殊
- 所有的假设共同构成了假设空间，学习的过程就可以看作是在假设空间中搜索最能**匹配(fit)**训练集的假设
- 有时候会出现多个假设都能匹配训练集的情形，这些假设的集合就称为**版本空间(version space)** 
- 版本空间是假设空间的子空间

### 1.4 归纳偏好

- 算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”(inductive bias)

- **NFL定理(No Free Lunch Theorem)**，误差的期望与算法无关（注意前提）

  ["No Free Lunch Theorems for Optimization"](http://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf)

- 要谈论算法的优劣，必须结合具体问题！

- 学习算法的归纳偏好和问题是否相配，往往起到决定性的作用

### 1.5 发展历程

- 让机器拥有知识，才能拥有智能
- 从样例中学习，广义的归纳学习

### 1.6 应用现状

- 机器学习和数据库是数据挖掘的两大支撑
- 理解人类如何学习
